# Thesis-GPT Env â€” Environnement local (Mac, Ollama)

Cet environnement te permet de travailler ton mÃ©moire appliquÃ© avec un assistant GPT **local** (sans cloud), basÃ© sur :
- **RAG** (Recherche AugmentÃ©e par GÃ©nÃ©ration) â†’ indexe tes PDF/notes et pose des questions dessus.
- **Presets de modÃ¨les** pour alterner entre 3 modes :
  - **Coach** â†’ itÃ©rations rapides (Qwen2.5 14B ou Llama3.1 13B)
  - **Sparring** â†’ structuration/profondeur (Qwen2.5 32B)
  - **Reviewer** â†’ audit final exigeant (Llama3.1 70B, quantisation lÃ©gÃ¨re Q2_K)

---

## ğŸš€ Installation

### 1) DÃ©pendances
- macOS (testÃ© sur Apple Silicon, 48 Go RAM ok)
- Python 3.10+
- [Ollama](https://ollama.com/) (serveur de modÃ¨les locaux)

### 2) PrÃ©parer lâ€™environnement
```bash
# Cloner ou crÃ©er le dossier
cd ~/Documents/thesis-gpt-env

# CrÃ©er et activer lâ€™environnement virtuel Python
python3 -m venv .venv
source .venv/bin/activate

# Installer les dÃ©pendances
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt

## Prompts

Toutes les commandes passent par make.
âš¡ Ajoute q="..." pour poser ta question.

Indexer tes sources
make ingest


â†’ Parcourt ./data/ (PDF, .md, .txt), crÃ©e une base Chroma pour le RAG.

Mode Coach (rapide, cadrage)
make coach q="Propose-moi 3 problÃ©matiques possibles sur lâ€™usage de lâ€™IA gÃ©nÃ©rative"


Utilise Qwen2.5 14B (ou Llama3.1 13B selon config).

Objectif : clarifier, proposer un plan, dÃ©couper le travail.

Mode Sparring (rigueur, alternatives)
make sparring q="Voici ma problÃ©matique provisoire : â€¦ Propose 2 alternatives et critique-la"


Utilise Qwen2.5 32B.

Objectif : stress-test de la problÃ©matique, proposer alternatives et hypothÃ¨ses.

Mode Reviewer (audit final)
make reviewer q="Ã‰value mon protocole mÃ©thodologique : entretiens + analyse comparative"


Utilise Llama3.1 70B (Q2_K).

Objectif : audit type jury (mÃ©thodo, biais, Ã©thique, RGPD).

Mode Ask (choisir explicitement un modÃ¨le)
make ask model=qwen2.5:32b-instruct q="Comment formuler une hypothÃ¨se testable Ã  partir de X ?"


Tu forces le modÃ¨le.

Exemple : llama3.1:13b-instruct, qwen2.5:14b-instruct, etc.

## ğŸ›  Workflow conseillÃ©

Coach â†’ cadrer la problÃ©matique, obtenir un plan initial.

Sparring â†’ tester la soliditÃ©, obtenir variantes & critiques.

Reviewer â†’ audit final avant rÃ©daction.

ğŸ’¡ Sauvegarde rÃ©guliÃ¨rement tes versions (problÃ©matique, plan, hypothÃ¨ses) dans ./data/*.md, puis refais make ingest â†’ Ã§a donne une mÃ©moire longue durÃ©e Ã  ton assistant via RAG.

## ğŸ§  MÃ©moire locale courte
- Le script garde les **3 derniers Ã©changes** dans `outputs/memory.json`.
- Cette mÃ©moire est **rÃ©injectÃ©e** en tÃªte du prompt (section â€œMÃ‰MOIRE RÃ‰CENTEâ€) pour conserver le fil.
- Rien nâ€™est envoyÃ© au cloud.

## ğŸ“ Exports Markdown
- Chaque rÃ©ponse est sauvegardÃ©e dans `outputs/` sous la forme:
  `YYYYMMDD-HHMMSS__{preset_ou_model}.md`
- Contient la question + la rÃ©ponse complÃ¨te (utile pour relire/annoter).

## ğŸ” Citations obligatoires
- Le prompt exige de **citer** `[Source: chemin p.X]` pour tout point fondÃ© sur le CONTEXTE RAG.
- En lâ€™absence de preuve, marquer **[Ã  vÃ©rifier]**.
